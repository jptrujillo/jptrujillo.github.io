---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am an assistant professor at the Institute for Logic, Language & Computation (ILLC) at the University of Amsterdam (UvA). My position is specifically in *Virtual Simulation of Human Conversational Behavior*, and is embedded in the [Language Sciences for Social Good](https://language-science.nl/) consortium. 

Previously I worked as postdoc with Judith Holler in the Communication in Social Interaction (CoSI) group, based at the Donders Centre for Cognition and Max Planck Institute for Psycholinguistics. My research largely focused on using motion tracking to capture movement kinematics and their role in social communicative behavior, and in particular for the signaling of social actions.
Apart from research, I enjoy art (drawing, watercolor, and urban sketching, mostly), bouldering,  (barefoot) running, martial arts, gaming, and spending time with my kid.

In between research and leisure, I also very much like solving problems in Python, and generally working on methodology and making quantitative methods more accessible. In line with this, I'm part of the [ENVISIONbox](envisionbox.org) team, where we develop methods tutorials and open code, and provide workshops and summer/winterschools.

Current Research Interests
======
Overall, my research aims to understand how we use the ensemble of visual and vocal modalities available to us in order to communicate. 
How do we orchestrate, face, head, body, hands, and speech together into one multimodal whole, and how do others make sense of this? 
How do we adapt this complex array of behaviors to different contexts? 
How is neurodiversity reflected in different styles of communication, and how does this impact social interaction?

Methods: Expertise and Interests
======
Motion tracking, gesture annotation, kinematic analysis, virtual animation, fMRI, interaction dynamics 
